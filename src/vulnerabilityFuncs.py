import pandas as pd
import os
from openpyxl import Workbook
import numpy as np
from collections import Counter
import pylab as pl
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import GridSearchCV
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import matplotlib.pyplot as plt

#Initialise repositories
_projroot = os.path.abspath('.')
_datadir = os.path.join(_projroot, 'data')
_preprocesseddir = os.path.join(_datadir, 'preprocesseddata')
_rawdir = os.path.join(_datadir, 'rawdata')

class Vulnerability():
    def __init__(self):
        self.target = {}
        self.features = {}
        self.results = {}
        self.models = {}
        self.vulnerability = {}
        self.variance = {}
        self.intercepts = {}

    def read_file(self, path, prefix, sheetname = None):
        
        featurePath = os.path.join(path, '%s_features.xlsx'%prefix)
        targetPath = os.path.join(path, '%s_target.xlsx'%prefix)

        for item in sheetname:
            if item == 'original':
                self.features_original = pd.read_excel(featurePath, sheet_name = item)
                self.features_original = self.drop_unnamed(self.features_original)
                self.target_original = pd.read_excel(targetPath, sheet_name = item)['Target']

            else:
                self.features[item] = pd.read_excel(featurePath, sheet_name = item)
                self.features[item] = self.drop_unnamed(self.features[item])
                self.target[item] = pd.read_excel(targetPath, sheet_name = item)['Target']

        return
    
    def drop_unnamed(self, dataframe):
        try:
            dataframe = dataframe.drop('Unnamed: 0', axis = 1)
        except KeyError:
            pass
    
        return dataframe
    
    def elastic_regression(self, C = [0.001,0.01,1,10,100,1000], L1_ratio = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9], tolerance = 0.01, max_iters = 5000, feature = None):

        C = np.array(C)
        L1_ratio = np.array(L1_ratio)

        if type(feature) == str:
            coeffs = np.array([])
            intercepts = np.array([])
            for key in self.features:
                lr = LogisticRegression(solver = 'saga',penalty = 'elasticnet', tol = tolerance, max_iter = max_iters)
                parameters = {
                    'C' : C,
                    'l1_ratio' : L1_ratio
                }
                cv = GridSearchCV(lr, parameters, cv = 5)
                cv.fit(self.features[key][feature].values.reshape(-1,1), self.target[key])
                model = cv.best_estimator_
                intercepts = np.append(intercepts, model.intercept_)
                coeffs = np.append(coeffs, model.coef_[0])
            
            coeff = coeffs.mean()
            intercept = intercepts.mean()
            return coeff, intercept

        else:
            for key in self.features:
                lr = LogisticRegression(solver = 'saga',penalty = 'elasticnet', tol = tolerance, max_iter = max_iters)
                parameters = {
                    'C' : C,
                    'l1_ratio' : L1_ratio
                }
                cv = GridSearchCV(lr, parameters, cv = 5)
                cv.fit(self.features[key], self.target[key])
                self.results[key] = cv.cv_results_
                self.models[key] = cv.best_estimator_
                self.intercepts[key] =  self.models[key].intercept_
            return
    
    def save_coefficients(self, directory, filename):
        
        for key in self.models:
            try:
                dataframe = dataframe.join(pd.DataFrame(self.models[key].coef_[0], self.features[key].columns, columns=[key]), how = 'outer')
            except UnboundLocalError:
                dataframe = pd.DataFrame(self.models[key].coef_[0], self.features[key].columns, columns=[key])

        dataframe = dataframe.append(pd.DataFrame.from_dict(self.intercepts))
        dataframe.loc['intercept'] = dataframe.loc[0]
        dataframe = dataframe.drop(0)
        self.coeffs = dataframe
        print(self.coeffs)
        self.probabilities = np.exp(self.coeffs)/(1+np.exp(self.coeffs))
        self.coeff_info = self.coeffs.transpose().describe().transpose()
        self.probs_info = self.probabilities.transpose().describe().transpose()

        wb = Workbook()
        wb.save(filename = os.path.join(directory, '%s.xlsx'%filename))
        with pd.ExcelWriter(os.path.join(directory, '%s.xlsx'%filename), engine="openpyxl", mode = 'a') as writer:
            self.coeffs.to_excel(writer, sheet_name = 'coefficients')
            self.coeff_info.to_excel(writer, sheet_name = 'coefficient info')
            self.probabilities.to_excel(writer, sheet_name = 'probabilities')
            self.probs_info.to_excel(writer, sheet_name = 'probability info')

        return
    
    def find_variance(self):
        for column in self.coeffs.columns:
            beta_diag = np.diag(self.coeffs[column].to_numpy())
            self.features[column]['intercept'] = np.ones(len(self.features[column]))
            X = self.features[column].to_numpy()
            print(np.shape(X))
            covariance_matrix = np.cov(X,beta_diag)
            variance = np.diagonal(covariance_matrix)
            self.variance[column]= np.mean(variance)
        
        self.variance['mean'] = np.array(list(self.variance.values())).mean()
        return self.variance
    
    def find_probability(self, input):
        return np.exp(input)/(1+np.exp(input))
    
    def find_confidence_interval(self, x, beta, intercept, alpha, model = 'mean'):
        input_upper = (x * beta) + intercept + (1-alpha/2) * np.sqrt(self.variance[model])
        upper = self.find_probability(input_upper)

        input_lower = x * beta + intercept - (1-alpha/2) * np.sqrt(self.variance[model])
        lower = self.find_probability(input_lower)

        return upper, lower

    def plot_feature(self, feature, title, xlabel, path, model= 'mean'):

        probability = np.array([])
        upper_bound = np.array([])
        lower_bound = np.array([])

        coef, intercept = self.elastic_regression(feature = 'AGE')

        X  = np.arange(0,1.001,0.001)
        X_true = X * self.features_original[feature].max()
        for x in X:
            input = (x * coef) + intercept
            probability = np.append(probability, self.find_probability(input))
            upper, lower = self.find_confidence_interval(x, coef, intercept, 0.05)
            upper_bound = np.append(upper_bound, upper)
            lower_bound = np.append(lower_bound, lower)
        
        plt.figure()
        plt.plot(X_true, probability, label = 'Probability')
        plt.plot(X_true, upper_bound, linestyle='dashed', label = '95\% confidence interval, upper')
        plt.plot(X_true, lower_bound, linestyle='dashed', label = '95\% confidence interval, lower' )
        plt.legend()
        plt.ylabel('Probability')
        plt.xlabel(xlabel)
        plt.title(title)
        plt.savefig(path, dpi = 600)
        plt.show()
        

        return



    
    def save_results(self, file):
        wb = Workbook()
        wb.save(filename = file)

        for key in self.results:
            df = pd.DataFrame.from_dict(self.results[key])
            with pd.ExcelWriter(file,engine="openpyxl", mode = 'a') as writer:
                df.to_excel(writer, sheet_name = key)
            
        return
    

    def plot_probability(self, x):
        pass

        

